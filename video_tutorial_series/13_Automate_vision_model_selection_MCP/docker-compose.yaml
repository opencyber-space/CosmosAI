version: "3.3"

services:
  # ---- MCP registry and model services ----
  ror:
    build: .
    command: python servers/mcp1_registry_of_registries.py
    ports: []                # no host exposure; internal only

  openos-assets:
    build: .
    command: python servers/mcp2_openos_assets.py
    ports: []

  pipeline-composer:
    build: .
    command: python servers/mcp3_pipeline_composer.py
    depends_on: [openos-assets]
    ports: []

  roadnet-assets:
    build: .
    command: python servers/mcp2_roadnet_assets.py
    ports: []

  aicenter-assets:
    build: .
    command: python servers/mcp2_aicenter_assets.py
    ports: []

  openos-models:
    build: .
    command: python servers/mcp4_openos_model_tools.py
    ports: []

  roadnet-models:
    build: .
    command: python servers/mcp4_roadnet_model_tools.py
    ports: []

  aicenter-models:
    build: .
    command: python servers/mcp4_aicenter_model_tools.py
    ports: []

  # ---- Chainlit UI ----
  # chainlit-ui:
  #   build:
  #     context: ./chainlit/mcp-vision-chainlit
  #     dockerfile: Dockerfile
  #   ports:
  #     - "8501:8000"          # expose Chainlit UI on port 8501
  #   environment:
  #     - OPENAI_API_KEY=${OPENAI_API_KEY}
  #     - REGISTRY_URL=http://nginx/mcp
  #     - MODEL=gpt-4o-mini
  #   volumes:
  #     - ./chainlit/mcp-vision-chainlit:/app
  #   depends_on:
  #     - nginx

  # ---- Nginx reverse-proxy ----
  nginx:
    image: nginx:1.25-alpine
    volumes:
      - ./nginx/mcp.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "8080:80"          # expose MCP services on port 8080
    depends_on:
      - ror
      - openos-assets
      - pipeline-composer
      - roadnet-assets
      - aicenter-assets
      - openos-models
      - roadnet-models
      - aicenter-models
