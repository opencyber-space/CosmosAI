{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b14b2a7",
   "metadata": {},
   "source": [
    "# A Developer's Guide to Block Load Balancing in AIOS\n",
    "\n",
    "Welcome to this guide on the **Block Load Balancer** feature in AIOS. The load balancer is a critical policy that distributes incoming inference requests across multiple block replicas. This optimizes performance, ensures high availability, and makes efficient use of your computational resources.\n",
    "\n",
    "Below is a visual overview of the load balancing process, where incoming requests are intelligently distributed across available model replicas.\n",
    "\n",
    "<!--- ![Load Balancing Process](loadbalancer.gif) -->\n",
    "<!-- <img src=\"loadbalancer.gif\" width=\"400\" height=\"150\"> -->\n",
    "<img src=\"loadbalancer.png\" alt=\"Custom LoadBalancer\" width=\"800\" height=\"800\"> \n",
    "\n",
    "For a deep dive into the concepts, you can refer to the official documentation:\n",
    "### where this comes in the overall scheme of things with Architecture diagram\n",
    "- [Block Concepts](https://github.com/OpenCyberspace/OpenOS.AI-Documentation/blob/main/block/block.md)\n",
    "- [Block Load Balancer Concepts](https://github.com/OpenCyberspace/OpenOS.AI-Documentation/blob/main/block/block.md#block-load-balancer-executor)\n",
    "\n",
    "The process involves:\n",
    "1.  **Building a Load Balancer Policy**: Defining the logic for request distribution in a Python class.\n",
    "2.  **Testing the Policy**: Running unit tests to ensure the distribution logic is correct.\n",
    "3.  **Deploying the Policy**: Uploading and registering the policy with AIOS.\n",
    "4.  **Triggering and Observing Distribution**: Simulating a workload and monitoring the system to see the load balancer in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228830f2",
   "metadata": {},
   "source": [
    "## The AIOS Policy System\n",
    "\n",
    "Before we build our load balancer, it's important to understand the **AIOS Policy System**. Policies are pluggable, versioned, and reusable modules that control the runtime behavior of Blocks. They allow you to customize how AIOS manages resources, routes traffic, and ensures stability without modifying the core application code.\n",
    "\n",
    "AIOS uses a chain of policies to manage a Block's lifecycle. Common policy types include:\n",
    "- **`clusterAllocator`**: Selects a cluster to run the block.\n",
    "- **`resourceAllocator`**: Assigns specific nodes and hardware.\n",
    "- **`loadBalancer`**: Distributes incoming requests among replicas.\n",
    "- **`stabilityChecker`**: Monitors the health of a block.\n",
    "- **`autoscaler`**: Automatically adjusts the number of block replicas.\n",
    "\n",
    "In this tutorial, we will focus on creating a custom `loadBalancer` policy. For more information on the policy system, see the documentation:\n",
    "- [Policies System Overview](https://github.com/OpenCyberspace/OpenOS.AI-Documentation/blob/main/policies-system/policies-system.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114692b8",
   "metadata": {},
   "source": [
    "## 1. Building a Token-Based Load Balancer Policy\n",
    "\n",
    "Our load balancer will use a **token-based distribution** strategy. This is particularly effective for LLMs, where the number of tokens in a request is a good proxy for the computational cost. The policy will score each available replica based on its recent token workload and route new requests to the replica with the lowest score (i.e., the least busy).\n",
    "\n",
    "### The Logic of Token-Based Distribution\n",
    "The core idea is to:\n",
    "- **Calculate a \"load score\"** for each replica based on a weighted average of its input and output tokens per minute.\n",
    "- **Assign a higher weight to output tokens**, as generation is typically more computationally intensive than processing the input prompt.\n",
    "- **Select the replica with the lowest score** for the next incoming request, as it is presumed to be the least loaded.\n",
    "- **Implement session stickiness**, ensuring that all requests within the same session are routed to the same replica to maintain context.\n",
    "\n",
    "This approach intelligently distributes the load based on the actual work each replica is doing, leading to better overall throughput and latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6775f",
   "metadata": {},
   "source": [
    "The policy is defined within a class named `AIOSv1PolicyRule`. We will build this class step-by-step, explaining each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3853b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "import inspect\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2de93",
   "metadata": {},
   "source": [
    "### The `AIOSv1PolicyRule` Class and `__init__` Method\n",
    "\n",
    "This is the main class for our policy. The `__init__` method initializes the policy's state. It sets up logging and retrieves parameters like token weights and the averaging period from the policy's configuration. It also gets a reference to the `get_metrics` function, which is crucial for fetching the data needed to make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e6acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIOSv1PolicyRule:\n",
    "    def __init__(self, rule_id, settings, parameters):\n",
    "        self.rule_id = rule_id\n",
    "        self.settings = settings\n",
    "        self.parameters = parameters\n",
    "        self.logger = logging.getLogger(f\"TokenBasedDistributionPolicy-{self.rule_id}\")\n",
    "\n",
    "        self.output_token_weight = self.parameters.get(\"output_token_weight\", 0.9)\n",
    "        self.input_token_weight = self.parameters.get(\"input_token_weight\", 0.1)\n",
    "        self.averaging_period = self.parameters.get(\"averaging_period\", \"average_1m\")\n",
    "        self.allow_random_fallback = self.parameters.get(\"allow_random_fallback\", True)\n",
    "\n",
    "        self.metrics_function = self.settings.get(\"get_metrics\")\n",
    "        self.block_data = self.settings.get(\"block_data\")\n",
    "        self.cluster_data = self.settings.get(\"cluster_data\")\n",
    "        \n",
    "        self.session_ids_cache = {}\n",
    "        self.current_instances = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830935c",
   "metadata": {},
   "source": [
    "### The `_calculate_weighted_tokens` Method\n",
    "\n",
    "This helper method calculates a score for a given block instance based on its recent token usage. It combines the input and output tokens, applying the weights defined in our parameters, to produce a single score representing the instance's current load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3be3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIOSv1PolicyRule(AIOSv1PolicyRule): \n",
    "    def _calculate_weighted_tokens(self, instance_metrics: Dict[str, Any]) -> float:\n",
    "        input_tokens_rolling = instance_metrics.get(\"llm_input_tokens_per_minute_rolling\", {})\n",
    "        output_tokens_rolling = instance_metrics.get(\"llm_output_tokens_per_minute_rolling\", {})\n",
    "    \n",
    "        input_tokens = input_tokens_rolling.get(self.averaging_period, 0)\n",
    "        output_tokens = output_tokens_rolling.get(self.averaging_period, 0)\n",
    "    \n",
    "        return (self.input_token_weight * input_tokens) + (self.output_token_weight * output_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ffcb2",
   "metadata": {},
   "source": [
    "### The `_select_instance` Method\n",
    "\n",
    "This method is responsible for choosing the best instance to handle a new request. It fetches the latest metrics for all available instances, uses `_calculate_weighted_tokens` to score each one, and then selects the instance with the *lowest* score. If no metrics are available, it can fall back to selecting an instance at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265a8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIOSv1PolicyRule(AIOSv1PolicyRule): \n",
    "    def _select_instance(self) -> str:\n",
    "        if not self.current_instances:\n",
    "            self.logger.warning(\"No instances available for routing.\")\n",
    "            return None\n",
    "    \n",
    "        current_metrics = self.metrics_function()\n",
    "        block_metrics = current_metrics.get(\"block_metrics\", [])\n",
    "        \n",
    "        instance_scores = {}\n",
    "        if block_metrics:\n",
    "            self.logger.info(f\"Calculating scores for instances with metrics: {self.current_instances}\")\n",
    "            for instance_metric in block_metrics:\n",
    "                instance_id = instance_metric.get(\"instanceId\")\n",
    "                if instance_id and instance_id in self.current_instances:\n",
    "                    score = self._calculate_weighted_tokens(instance_metric)\n",
    "                    instance_scores[instance_id] = score\n",
    "                    self.logger.info(f\"  - Instance '{instance_id}': score = {score:.2f}\")\n",
    "    \n",
    "        if not instance_scores:\n",
    "            self.logger.warning(\"No instance scores calculated from metrics.\")\n",
    "            if self.allow_random_fallback and self.current_instances:\n",
    "                chosen_instance = random.choice(self.current_instances)\n",
    "                self.logger.info(f\"Randomly selected instance: '{chosen_instance}' as fallback is enabled.\")\n",
    "                return chosen_instance\n",
    "            else:\n",
    "                self.logger.warning(\"Cannot select an instance: No scores and random fallback is disabled or no instances available.\")\n",
    "                return None\n",
    "        else:\n",
    "            chosen_instance = min(instance_scores, key=instance_scores.get)\n",
    "            self.logger.info(f\"Final scores: {instance_scores}. Chosen instance with lowest score: '{chosen_instance}'\")\n",
    "            return chosen_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6431ed9",
   "metadata": {},
   "source": [
    "### The `eval` Method\n",
    "\n",
    "This is the main entry point for the policy's logic. It's called by the AIOS Load Balancer for each incoming request. It first checks for \"session stickiness\"—if the request is part of an existing session, it routes it to the same instance as before. If it's a new request, it calls `_select_instance` to find the best destination. Finally, it caches the decision for new sessions and returns the chosen instance ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f704ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIOSv1PolicyRule(AIOSv1PolicyRule):\n",
    "    def eval(self, parameters: Dict[str, Any], input_data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        self.logger.info(f\"Starting token-based distribution evaluation. Input data keys: {list(input_data.keys())}\")\n",
    "        try:\n",
    "            if not callable(self.metrics_function):\n",
    "                self.logger.error(\"'get_metrics' function not found. Cannot determine instances or metrics.\")\n",
    "                return {\"instance_id\": None, \"reason\": \"Metrics function not configured.\"}\n",
    "            \n",
    "            latest_instances = input_data.get(\"instances\", [])\n",
    "    \n",
    "            if set(latest_instances) != set(self.current_instances):\n",
    "                self.logger.info(f\"Instance list changed from {self.current_instances} to {latest_instances}. Updating session cache.\")\n",
    "                \n",
    "                stale_sessions = [\n",
    "                    session_id for session_id, instance_id in self.session_ids_cache.items()\n",
    "                    if instance_id not in latest_instances\n",
    "                ]\n",
    "                \n",
    "                if stale_sessions:\n",
    "                    self.logger.info(f\"Removing stale sessions from cache: {stale_sessions}\")\n",
    "                    for session_id in stale_sessions:\n",
    "                        del self.session_ids_cache[session_id]\n",
    "    \n",
    "                self.current_instances = latest_instances\n",
    "    \n",
    "            if not self.current_instances:\n",
    "                self.logger.warning(\"No instances available for routing.\")\n",
    "                return {\"instance_id\": None, \"reason\": \"No available instances.\"}\n",
    "    \n",
    "            packet = input_data.get(\"packet\")\n",
    "            if packet:\n",
    "                session_id = getattr(packet, \"session_id\", None)\n",
    "                if session_id and session_id in self.session_ids_cache:\n",
    "                    cached_instance = self.session_ids_cache[session_id]\n",
    "                    if cached_instance in self.current_instances:\n",
    "                        self.logger.info(f\"Session '{session_id}' found in cache. Routing to instance '{cached_instance}'.\")\n",
    "                        return {\"instance_id\": cached_instance}\n",
    "                    else:\n",
    "                        self.logger.info(f\"Cached instance '{cached_instance}' for session '{session_id}' is no longer active. Removing from cache.\")\n",
    "                        del self.session_ids_cache[session_id]\n",
    "    \n",
    "            chosen_instance = self._select_instance()\n",
    "    \n",
    "            if not chosen_instance:\n",
    "                self.logger.error(\"Failed to select an instance.\")\n",
    "                return {\"instance_id\": None, \"reason\": \"Instance selection failed.\"}\n",
    "    \n",
    "            if packet and getattr(packet, \"session_id\", None):\n",
    "                session_id = packet.session_id\n",
    "                self.logger.info(f\"Caching session '{session_id}' to instance '{chosen_instance}'.\")\n",
    "                self.session_ids_cache[session_id] = chosen_instance\n",
    "    \n",
    "            return {\"instance_id\": chosen_instance}\n",
    "    \n",
    "        except Exception as e:\n",
    "            self.logger.exception(f\"An unexpected error occurred during evaluation: {e}\")\n",
    "            if self.current_instances and self.allow_random_fallback:\n",
    "                chosen_instance = random.choice(self.current_instances)\n",
    "                self.logger.warning(f\"Error occurred. Falling back to random instance: {chosen_instance}\")\n",
    "                return {\"instance_id\": chosen_instance}\n",
    "            \n",
    "            return {\"instance_id\": None, \"reason\": \"An error occurred and random fallback is disabled.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbeff3",
   "metadata": {},
   "source": [
    "### The `management` Method\n",
    "\n",
    "This method handles administrative tasks and special commands that aren't part of the regular request evaluation flow. For example, it can respond to health checks or pre-assign an instance for a long-lived streaming session before the first request even arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b172ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIOSv1PolicyRule(AIOSv1PolicyRule):\n",
    "    def management(self, action: str, data: dict) -> dict:\n",
    "        self.logger.info(f\"Management action received: {action} with data: {data}\")\n",
    "        if action == \"health_check\":\n",
    "            return {\"instances\": self.current_instances, \"status\": \"healthy\"}\n",
    "        elif action == \"get_current_mapping\":\n",
    "            return {\"mapping\": self.session_ids_cache}\n",
    "        elif action == \"assign_streaming\":\n",
    "            session_id = data.get(\"session_id\")\n",
    "            latest_instances = data.get(\"instances\", [])\n",
    "            if set(latest_instances) != set(self.current_instances):\n",
    "                self.logger.info(f\"Instance list changed from {self.current_instances} to {latest_instances}. Updating session cache.\")\n",
    "                \n",
    "                stale_sessions = [\n",
    "                    session_id for session_id, instance_id in self.session_ids_cache.items()\n",
    "                    if instance_id not in latest_instances\n",
    "                ]\n",
    "                \n",
    "                if stale_sessions:\n",
    "                    self.logger.info(f\"Removing stale sessions from cache: {stale_sessions}\")\n",
    "                    for session_id in stale_sessions:\n",
    "                        del self.session_ids_cache[session_id]\n",
    "    \n",
    "                self.current_instances = latest_instances\n",
    "    \n",
    "            if not session_id:\n",
    "                self.logger.error(\"'session_id' not provided for 'assign_streaming' action.\")\n",
    "                return {\"status\": \"error\", \"reason\": \"session_id is required.\"}\n",
    "    \n",
    "            if session_id in self.session_ids_cache:\n",
    "                cached_instance = self.session_ids_cache[session_id]\n",
    "                if cached_instance in self.current_instances:\n",
    "                    self.logger.info(f\"Session '{session_id}' already assigned to '{cached_instance}'.\")\n",
    "                    return {\"instance_id\": cached_instance, \"status\": \"ok\"}\n",
    "                else:\n",
    "                    self.logger.info(f\"Cached instance '{cached_instance}' for session '{session_id}' is no longer active. Re-assigning.\")\n",
    "                    del self.session_ids_cache[session_id]\n",
    "    \n",
    "            chosen_instance = self._select_instance()\n",
    "    \n",
    "            if chosen_instance:\n",
    "                self.logger.info(f\"Pre-allocating instance '{chosen_instance}' for streaming session '{session_id}'.\")\n",
    "                self.session_ids_cache[session_id] = chosen_instance\n",
    "                return {\"instance_id\": chosen_instance, \"status\": \"ok\"}\n",
    "            else:\n",
    "                self.logger.error(f\"Failed to select an instance for session '{session_id}'.\")\n",
    "                return {\"instance_id\": None, \"status\": \"error\", \"reason\": \"Instance selection failed.\"}\n",
    "    \n",
    "        self.logger.warning(f\"Unknown management action received: {action}\")\n",
    "        return {\"status\": \"unknown_action\", \"reason\": f\"Action '{action}' is not supported.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376021b",
   "metadata": {},
   "source": [
    "## 2. Testing the Policy\n",
    "\n",
    "We'll write a unit test to ensure our policy correctly scores blocks based on their token load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02dd27ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_select_instance_with_lowest_score (__main__.TestTokenBasedLoadBalancer.test_select_instance_with_lowest_score) ... 2025-07-30 09:33:51,097 - INFO - Starting token-based distribution evaluation. Input data keys: ['instances', 'packet']\n",
      "2025-07-30 09:33:51,097 - INFO - Instance list changed from [] to ['instance-1', 'instance-2', 'instance-3']. Updating session cache.\n",
      "2025-07-30 09:33:51,098 - INFO - Calculating scores for instances with metrics: ['instance-1', 'instance-2', 'instance-3']\n",
      "2025-07-30 09:33:51,098 - INFO -   - Instance 'instance-1': score = 910.00\n",
      "2025-07-30 09:33:51,098 - INFO -   - Instance 'instance-2': score = 455.00\n",
      "2025-07-30 09:33:51,099 - INFO -   - Instance 'instance-3': score = 1370.00\n",
      "2025-07-30 09:33:51,099 - INFO - Final scores: {'instance-1': 910.0, 'instance-2': 455.0, 'instance-3': 1370.0}. Chosen instance with lowest score: 'instance-2'\n",
      "ok\n",
      "test_session_stickiness (__main__.TestTokenBasedLoadBalancer.test_session_stickiness) ... 2025-07-30 09:33:51,101 - INFO - Starting token-based distribution evaluation. Input data keys: ['instances', 'packet']\n",
      "2025-07-30 09:33:51,101 - INFO - Instance list changed from [] to ['instance-1', 'instance-2']. Updating session cache.\n",
      "2025-07-30 09:33:51,102 - INFO - Calculating scores for instances with metrics: ['instance-1', 'instance-2']\n",
      "2025-07-30 09:33:51,102 - INFO -   - Instance 'instance-1': score = 910.00\n",
      "2025-07-30 09:33:51,102 - INFO -   - Instance 'instance-2': score = 455.00\n",
      "2025-07-30 09:33:51,103 - INFO - Final scores: {'instance-1': 910.0, 'instance-2': 455.0}. Chosen instance with lowest score: 'instance-2'\n",
      "2025-07-30 09:33:51,103 - INFO - Caching session 'session-123' to instance 'instance-2'.\n",
      "2025-07-30 09:33:51,104 - INFO - Starting token-based distribution evaluation. Input data keys: ['instances', 'packet']\n",
      "2025-07-30 09:33:51,104 - INFO - Session 'session-123' found in cache. Routing to instance 'instance-2'.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3279423/2187012284.py:70: DeprecationWarning: unittest.makeSuite() is deprecated and will be removed in Python 3.13. Please use unittest.TestLoader.loadTestsFromTestCase() instead.\n",
      "  suite.addTest(unittest.makeSuite(TestTokenBasedLoadBalancer))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest,sys\n",
    "from unittest.mock import MagicMock, Mock\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout  # Ensure logs go to the notebook output\n",
    ")\n",
    "\n",
    "class TestTokenBasedLoadBalancer(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.rule_id = \"test-lb-rule\"\n",
    "        self.settings = {}\n",
    "        self.parameters = {\n",
    "            \"output_token_weight\": 0.9,\n",
    "            \"input_token_weight\": 0.1,\n",
    "            \"averaging_period\": \"average_1m\",\n",
    "            \"allow_random_fallback\": True\n",
    "        }\n",
    "\n",
    "    def test_select_instance_with_lowest_score(self):\n",
    "        # Mock metrics collector\n",
    "        mock_metrics_collector = MagicMock(return_value={\n",
    "            \"block_metrics\": [\n",
    "                {\"instanceId\": \"instance-1\", \"llm_input_tokens_per_minute_rolling\": {\"average_1m\": 100}, \"llm_output_tokens_per_minute_rolling\": {\"average_1m\": 1000}}, # Score: 910\n",
    "                {\"instanceId\": \"instance-2\", \"llm_input_tokens_per_minute_rolling\": {\"average_1m\": 50}, \"llm_output_tokens_per_minute_rolling\": {\"average_1m\": 500}},   # Score: 455\n",
    "                {\"instanceId\": \"instance-3\", \"llm_input_tokens_per_minute_rolling\": {\"average_1m\": 200}, \"llm_output_tokens_per_minute_rolling\": {\"average_1m\": 1500}}  # Score: 1370\n",
    "            ]\n",
    "        })\n",
    "        self.settings[\"get_metrics\"] = mock_metrics_collector\n",
    "        \n",
    "        policy = AIOSv1PolicyRule(self.rule_id, self.settings, self.parameters)\n",
    "        input_data = {\"instances\": [\"instance-1\", \"instance-2\", \"instance-3\"], \"packet\": None}\n",
    "        \n",
    "        result = policy.eval({}, input_data, {})\n",
    "        self.assertEqual(result[\"instance_id\"], \"instance-2\")\n",
    "\n",
    "    def test_session_stickiness(self):\n",
    "        # Mock metrics collector\n",
    "        mock_metrics_collector = MagicMock(return_value={\n",
    "            \"block_metrics\": [\n",
    "                {\"instanceId\": \"instance-1\", \"llm_input_tokens_per_minute_rolling\": {\"average_1m\": 100}, \"llm_output_tokens_per_minute_rolling\": {\"average_1m\": 1000}},\n",
    "                {\"instanceId\": \"instance-2\", \"llm_input_tokens_per_minute_rolling\": {\"average_1m\": 50}, \"llm_output_tokens_per_minute_rolling\": {\"average_1m\": 500}}\n",
    "            ]\n",
    "        })\n",
    "        self.settings[\"get_metrics\"] = mock_metrics_collector\n",
    "        \n",
    "        policy = AIOSv1PolicyRule(self.rule_id, self.settings, self.parameters)\n",
    "        \n",
    "        # First call, should select instance-2 (lowest score) and cache it\n",
    "        packet1 = Mock()\n",
    "        packet1.session_id = \"session-123\"\n",
    "        input_data1 = {\"instances\": [\"instance-1\", \"instance-2\"], \"packet\": packet1}\n",
    "        result1 = policy.eval({}, input_data1, {})\n",
    "        self.assertEqual(result1[\"instance_id\"], \"instance-2\")\n",
    "        \n",
    "        # Second call with the same session_id, should return the cached instance-2\n",
    "        # even if metrics change to make instance-1 look better\n",
    "        mock_metrics_collector.return_value[\"block_metrics\"][1][\"llm_output_tokens_per_minute_rolling\"][\"average_1m\"] = 2000\n",
    "        \n",
    "        packet2 = Mock()\n",
    "        packet2.session_id = \"session-123\"\n",
    "        input_data2 = {\"instances\": [\"instance-1\", \"instance-2\"], \"packet\": packet2}\n",
    "        result2 = policy.eval({}, input_data2, {})\n",
    "        self.assertEqual(result2[\"instance_id\"], \"instance-2\")\n",
    "\n",
    "# Run the tests\n",
    "suite = unittest.TestSuite()\n",
    "suite.addTest(unittest.makeSuite(TestTokenBasedLoadBalancer))\n",
    "runner = unittest.TextTestRunner(stream=sys.stdout, verbosity=2)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107584db",
   "metadata": {},
   "source": [
    "## 3. Deploying the Policy\n",
    "\n",
    "With the policy tested, we can now deploy it to AIOS. This involves three steps: Assembling the policy, uploading the policy package (`tokenloadbalancer.zip`) and then registering it with the AIOS Policy System."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c81041",
   "metadata": {},
   "source": [
    "### a. Assembling the Policy for Deployment\n",
    "\n",
    "Now that we have defined all the methods of our `AIOSv1PolicyRule` class, we need to assemble them into a single script and package it correctly for deployment. The policy must be contained within a `code` directory, which includes the `function.py` file and a `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eeed68c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/function.py and code/requirements.txt created successfully.\n",
      "import random\n",
      "import logging\n",
      "from typing import Dict, Any\n",
      "\n",
      "class AIOSv1PolicyRule:\n",
      "    def __init__(self, rule_id, settings, parameters):\n",
      "        \"\"\"\n",
      "        Initializes the Token-Based Distribution Policy.\n",
      "\n",
      "        Args:\n",
      "            rule_id (str): Unique identifier for the rule.\n",
      "            settings (dict): Configuration settings for the rule.\n",
      "            parameters (dict): Parameters defining the rule's behavior.\n",
      "        \"\"\"\n",
      "        self.rule_id = rule_id\n",
      "        self.settings = settings\n",
      "        self.parameters = parameters\n",
      "        self.logger = logging.getLogger(f\"TokenBasedDistributionPolicy-{self.rule_id}\")\n",
      "\n",
      "        # Weights for token calculation\n",
      "        self.output_token_weight = self.parameters.get(\"output_token_weight\", 0.9)\n",
      "        self.input_token_weight = self.parameters.get(\"input_token_weight\", 0.1)\n",
      "        self.averaging_period = self.parameters.get(\"averaging_period\", \"average_1m\")\n",
      "        self.allow_random_fallback = self.parameters.get(\"allow_random_fallback\", True)\n",
      "\n",
      "        self.metrics_function = self.settings.get(\"get_metrics\")\n",
      "        self.block_data = self.settings.get(\"block_data\")\n",
      "        self.cluster_data = self.settings.get(\"cluster_data\")\n",
      "        \n",
      "        self.session_ids_cache = {}\n",
      "        self.current_instances = []\n",
      "\n",
      "    def _calculate_weighted_tokens(self, instance_metrics: Dict[str, Any]) -> float:\n",
      "        \"\"\"Calculates the weighted token score for an instance.\"\"\"\n",
      "        input_tokens_rolling = instance_metrics.get(\"llm_input_tokens_per_minute_rolling\", {})\n",
      "        output_tokens_rolling = instance_metrics.get(\"llm_output_tokens_per_minute_rolling\", {})\n",
      "\n",
      "        input_tokens = input_tokens_rolling.get(self.averaging_period, 0)\n",
      "        output_tokens = output_tokens_rolling.get(self.averaging_period, 0)\n",
      "\n",
      "        return (self.input_token_weight * input_tokens) + (self.output_token_weight * output_tokens)\n",
      "\n",
      "    def _select_instance(self) -> str:\n",
      "        \"\"\"Selects the best instance based on token metrics.\"\"\"\n",
      "        if not self.current_instances:\n",
      "            self.logger.warning(\"No instances available for routing.\")\n",
      "            return None\n",
      "\n",
      "        current_metrics = self.metrics_function()\n",
      "        block_metrics = current_metrics.get(\"block_metrics\", [])\n",
      "        \n",
      "        instance_scores = {}\n",
      "        if block_metrics:\n",
      "            self.logger.info(f\"Calculating scores for instances with metrics: {self.current_instances}\")\n",
      "            for instance_metric in block_metrics:\n",
      "                instance_id = instance_metric.get(\"instanceId\")\n",
      "                if instance_id and instance_id in self.current_instances:\n",
      "                    score = self._calculate_weighted_tokens(instance_metric)\n",
      "                    instance_scores[instance_id] = score\n",
      "                    self.logger.info(f\"  - Instance '{instance_id}': score = {score:.2f}\")\n",
      "\n",
      "        if not instance_scores:\n",
      "            self.logger.warning(\"No instance scores calculated from metrics.\")\n",
      "            if self.allow_random_fallback and self.current_instances:\n",
      "                chosen_instance = random.choice(self.current_instances)\n",
      "                self.logger.info(f\"Randomly selected instance: '{chosen_instance}' as fallback is enabled.\")\n",
      "                return chosen_instance\n",
      "            else:\n",
      "                self.logger.warning(\"Cannot select an instance: No scores and random fallback is disabled or no instances available.\")\n",
      "                return None\n",
      "        else:\n",
      "            # Choose the instance with the lowest score from the ones that had metrics\n",
      "            chosen_instance = min(instance_scores, key=instance_scores.get)\n",
      "            self.logger.info(f\"Final scores: {instance_scores}. Chosen instance with lowest score: '{chosen_instance}'\")\n",
      "            return chosen_instance\n",
      "\n",
      "    def eval(self, parameters: Dict[str, Any], input_data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Evaluates the policy to select an instance based on weighted token metrics.\n",
      "        \"\"\"\n",
      "        self.logger.info(f\"Starting token-based distribution evaluation. Input data keys: {list(input_data.keys())}\")\n",
      "        try:\n",
      "            if not callable(self.metrics_function):\n",
      "                self.logger.error(\"'get_metrics' function not found. Cannot determine instances or metrics.\")\n",
      "                return {\"instance_id\": None, \"reason\": \"Metrics function not configured.\"}\n",
      "            \n",
      "            # The instance list is provided in the input data for load balancing\n",
      "            latest_instances = input_data.get(\"instances\", [])\n",
      "\n",
      "            if set(latest_instances) != set(self.current_instances):\n",
      "                self.logger.info(f\"Instance list changed from {self.current_instances} to {latest_instances}. Updating session cache.\")\n",
      "                \n",
      "                # Instead of clearing the whole cache, remove only stale entries\n",
      "                stale_sessions = [\n",
      "                    session_id for session_id, instance_id in self.session_ids_cache.items()\n",
      "                    if instance_id not in latest_instances\n",
      "                ]\n",
      "                \n",
      "                if stale_sessions:\n",
      "                    self.logger.info(f\"Removing stale sessions from cache: {stale_sessions}\")\n",
      "                    for session_id in stale_sessions:\n",
      "                        del self.session_ids_cache[session_id]\n",
      "\n",
      "                self.current_instances = latest_instances\n",
      "\n",
      "            if not self.current_instances:\n",
      "                self.logger.warning(\"No instances available for routing.\")\n",
      "                return {\"instance_id\": None, \"reason\": \"No available instances.\"}\n",
      "\n",
      "            packet = input_data.get(\"packet\")\n",
      "            if packet:\n",
      "                session_id = getattr(packet, \"session_id\", None)\n",
      "                if session_id and session_id in self.session_ids_cache:\n",
      "                    cached_instance = self.session_ids_cache[session_id]\n",
      "                    if cached_instance in self.current_instances:\n",
      "                        self.logger.info(f\"Session '{session_id}' found in cache. Routing to instance '{cached_instance}'.\")\n",
      "                        return {\"instance_id\": cached_instance}\n",
      "                    else:\n",
      "                        self.logger.info(f\"Cached instance '{cached_instance}' for session '{session_id}' is no longer active. Removing from cache.\")\n",
      "                        del self.session_ids_cache[session_id]\n",
      "\n",
      "            # Select the best instance using the refactored helper method\n",
      "            chosen_instance = self._select_instance()\n",
      "\n",
      "            if not chosen_instance:\n",
      "                self.logger.error(\"Failed to select an instance.\")\n",
      "                return {\"instance_id\": None, \"reason\": \"Instance selection failed.\"}\n",
      "\n",
      "            if packet and getattr(packet, \"session_id\", None):\n",
      "                session_id = packet.session_id\n",
      "                self.logger.info(f\"Caching session '{session_id}' to instance '{chosen_instance}'.\")\n",
      "                self.session_ids_cache[session_id] = chosen_instance\n",
      "\n",
      "            return {\"instance_id\": chosen_instance}\n",
      "\n",
      "        except Exception as e:\n",
      "            self.logger.exception(f\"An unexpected error occurred during evaluation: {e}\")\n",
      "            # Fallback to random choice on error to maintain availability\n",
      "            if self.current_instances and self.allow_random_fallback:\n",
      "                chosen_instance = random.choice(self.current_instances)\n",
      "                self.logger.warning(f\"Error occurred. Falling back to random instance: {chosen_instance}\")\n",
      "                return {\"instance_id\": chosen_instance}\n",
      "            \n",
      "            return {\"instance_id\": None, \"reason\": \"An error occurred and random fallback is disabled.\"}\n",
      "\n",
      "    def management(self, action: str, data: dict) -> dict:\n",
      "        \"\"\"\n",
      "        Executes a custom management command.\n",
      "        \"\"\"\n",
      "        self.logger.info(f\"Management action received: {action} with data: {data}\")\n",
      "        if action == \"health_check\":\n",
      "            return {\"instances\": self.current_instances, \"status\": \"healthy\"}\n",
      "        elif action == \"get_current_mapping\":\n",
      "            return {\"mapping\": self.session_ids_cache}\n",
      "        elif action == \"assign_streaming\":\n",
      "            session_id = data.get(\"session_id\")\n",
      "            latest_instances = data.get(\"instances\", [])\n",
      "            if set(latest_instances) != set(self.current_instances):\n",
      "                self.logger.info(f\"Instance list changed from {self.current_instances} to {latest_instances}. Updating session cache.\")\n",
      "                \n",
      "                # Instead of clearing the whole cache, remove only stale entries\n",
      "                stale_sessions = [\n",
      "                    session_id for session_id, instance_id in self.session_ids_cache.items()\n",
      "                    if instance_id not in latest_instances\n",
      "                ]\n",
      "                \n",
      "                if stale_sessions:\n",
      "                    self.logger.info(f\"Removing stale sessions from cache: {stale_sessions}\")\n",
      "                    for session_id in stale_sessions:\n",
      "                        del self.session_ids_cache[session_id]\n",
      "\n",
      "                self.current_instances = latest_instances\n",
      "\n",
      "            if not session_id:\n",
      "                self.logger.error(\"'session_id' not provided for 'assign_streaming' action.\")\n",
      "                return {\"status\": \"error\", \"reason\": \"session_id is required.\"}\n",
      "\n",
      "            # If session is already cached, return the existing instance\n",
      "            if session_id in self.session_ids_cache:\n",
      "                cached_instance = self.session_ids_cache[session_id]\n",
      "                if cached_instance in self.current_instances:\n",
      "                    self.logger.info(f\"Session '{session_id}' already assigned to '{cached_instance}'.\")\n",
      "                    return {\"instance_id\": cached_instance, \"status\": \"ok\"}\n",
      "                else:\n",
      "                    self.logger.info(f\"Cached instance '{cached_instance}' for session '{session_id}' is no longer active. Re-assigning.\")\n",
      "                    del self.session_ids_cache[session_id]\n",
      "\n",
      "            # Select the best available instance\n",
      "            chosen_instance = self._select_instance()\n",
      "\n",
      "            if chosen_instance:\n",
      "                self.logger.info(f\"Pre-allocating instance '{chosen_instance}' for streaming session '{session_id}'.\")\n",
      "                self.session_ids_cache[session_id] = chosen_instance\n",
      "                return {\"instance_id\": chosen_instance, \"status\": \"ok\"}\n",
      "            else:\n",
      "                self.logger.error(f\"Failed to select an instance for session '{session_id}'.\")\n",
      "                return {\"instance_id\": None, \"status\": \"error\", \"reason\": \"Instance selection failed.\"}\n",
      "\n",
      "        self.logger.warning(f\"Unknown management action received: {action}\")\n",
      "        return {\"status\": \"unknown_action\", \"reason\": f\"Action '{action}' is not supported.\"}\n"
     ]
    }
   ],
   "source": [
    "# Create a requirements.txt file\n",
    "with open(\"code/requirements.txt\", \"w\") as f:\n",
    "    f.write(\"requests\") # No external dependencies for this policy\n",
    "\n",
    "print(\"code/function.py and code/requirements.txt created successfully.\")\n",
    "!cat code/function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faf890ef",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: code/ (stored 0%)\n",
      "  adding: code/function.py (deflated 78%)\n",
      "  adding: code/requirements.txt (stored 0%)\n",
      "  adding: code/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: code/.ipynb_checkpoints/function-checkpoint.py (deflated 78%)\n",
      "  adding: code/.ipynb_checkpoints/requirements-checkpoint.txt (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r tokenloadbalancer2.zip code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc62271d",
   "metadata": {},
   "source": [
    "### b. Upload the Policy Package\n",
    "\n",
    "First, we upload the `.zip` file containing our policy code to a location accessible by AIOS. The following `curl` command sends the file to an upload server, which makes it available via a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705dfc9f",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "!curl -X POST http://POLICYSTORESERVER:30186/upload -F \"file=@./tokenloadbalancer.zip\" -F \"path=.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9db0d",
   "metadata": {},
   "source": [
    "### c. Register the Policy\n",
    "\n",
    "Next, we register the policy with AIOS. This `curl` command sends a JSON payload to the policy registry endpoint. The payload contains metadata about our policy, including its name, version, and the URL where the code can be found (`\"code\": \"http://MANAGEMENTMASTER:32555/tokenloadbalancer.zip\"`). This tells AIOS how to find and execute our policy when it's attached to a block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2eba6b",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "!curl -X POST http://MANAGEMENTMASTER:30102/policy \\\\\n",
    "     -H \"Content-Type: application/json\" \\\\\n",
    "     -d '{ \\\\\n",
    "           \"name\": \"load_balancer\", \\\\\n",
    "           \"version\": \"1.0\", \\\\\n",
    "           \"release_tag\": \"stable\", \\\\\n",
    "           \"metadata\": {\"author\": \"admin\", \"category\": \"load_balancing\"}, \\\\\n",
    "           \"tags\": \"load_balancing,ai\", \\\\\n",
    "           \"code\": \"http://MANAGEMENTMASTER:32555/tokenloadbalancer.zip\", \\\\\n",
    "           \"code_type\": \"tar.xz\", \\\\\n",
    "           \"type\": \"policy\", \\\\\n",
    "           \"policy_input_schema\": {\"type\": \"object\", \"properties\": {\"blocks\": {\"type\": \"array\"}}}, \\\\\n",
    "           \"policy_output_schema\": {\"type\": \"object\", \"properties\": {\"scored_blocks\": {\"type\": \"array\"}}}, \\\\\n",
    "           \"policy_settings_schema\": {}, \\\\\n",
    "           \"policy_parameters_schema\": {}, \\\\\n",
    "           \"policy_settings\": {}, \\\\\n",
    "           \"policy_parameters\": {}, \\\\\n",
    "           \"description\": \"A policy for token-based load balancing.\", \\\\\n",
    "           \"functionality_data\": {\"strategy\": \"scoring-based\"}, \\\\\n",
    "           \"resource_estimates\": {} \\\\\n",
    "         }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0caa4b",
   "metadata": {},
   "source": [
    "Now, let's package our policy into a `tokenloadbalancer.zip` file for deployment. The zip file must contain the `code` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9938c0b9-feb8-4351-a5fd-d2720d49f5af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"head\": {\n",
      "        \"templateUri\": \"Parser/V1\",\n",
      "        \"parameters\": {}\n",
      "    },\n",
      "    \"body\": {\n",
      "        \"spec\": {\n",
      "            \"values\": {\n",
      "                \"mode\": \"allocate\",\n",
      "                \"blockId\": \"gemma3-27b-block\",\n",
      "                \"blockComponentURI\": \"model.gemma3-27b:1.0.0-stable\",\n",
      "                \"minInstances\": 1,\n",
      "                \"maxInstances\": 3,\n",
      "                \"blockInitData\": {\n",
      "                    \"model_name\": \"gemma-3-27b-it-UD-Q8_K_XL/gemma-3-27b-it-UD-Q8_K_XL.gguf\",\n",
      "                    \"clip_model_name\": \"gemma-3-27b-it-UD-Q8_K_XL/mmproj-F16.gguf\"\n",
      "                },\n",
      "                \"initSettings\": {\n",
      "                    \"tensor_parallel\": true,\n",
      "                    \"device\": \"cuda\",\n",
      "                    \"quantization_type\": \"fp16\",\n",
      "                    \"cleanup_enabled\":  true,\n",
      "                    \"cleanup_check_interval\": 60,\n",
      "                    \"cleanup_session_timeout\": 1800,\n",
      "                    \"gen_params\": {\n",
      "                        \"max_new_tokens\": 2048,\n",
      "                        \"temperature\": 0.2,\n",
      "                        \"top_k\": 50,\n",
      "                        \"top_p\": 0.95,\n",
      "                        \"repetition_penalty\": 1.1,\n",
      "                        \"do_sample\": true\n",
      "                    }\n",
      "                },\n",
      "                \"policyRulesSpec\": [\n",
      "                    {\n",
      "                        \"values\": {\n",
      "                            \"name\": \"clusterAllocator\",\n",
      "                            \"policyRuleURI\": \"cluster-selector:2.0-stable\",\n",
      "                            \"parameters\": {\n",
      "                                \"filter\": {\n",
      "                                    \"clusterQuery\": {\n",
      "                                        \"variable\": \"id\",\n",
      "                                        \"operator\": \"==\",\n",
      "                                        \"value\": \"gcp-cluster-2\"\n",
      "                                    }\n",
      "                                }\n",
      "                            },\n",
      "                            \"settings\": {\n",
      "                                \"max_candidates\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    },\n",
      "                    {\n",
      "                        \"values\": {\n",
      "                            \"name\": \"resourceAllocator\",\n",
      "                            \"policyRuleURI\": \"allocator:2.0-stable\",\n",
      "                            \"parameters\": {\n",
      "                                \"allocation_data\": {\n",
      "                                    \"node_id\": \"wc-gpu-node1\",\n",
      "                                    \"gpus\": [0]\n",
      "                                }\n",
      "                            },\n",
      "                            \"settings\": {\n",
      "                                \"selection_mode\": \"balanced\"\n",
      "                            }\n",
      "                        }\n",
      "                    },\n",
      "                    {\n",
      "                        \"values\": {\n",
      "                            \"name\": \"loadBalancer\",\n",
      "                            \"policyRuleURI\": \"load_balancer:2.0-stable\",\n",
      "                            \"parameters\": {\n",
      "                                \"cache_sessions\": true\n",
      "                            },\n",
      "                            \"settings\": {\n",
      "                                \"session_cache_size\": 2000\n",
      "                            }\n",
      "                        }\n",
      "                    },\n",
      "                    {\n",
      "                        \"values\": {\n",
      "                            \"name\": \"stabilityChecker\",\n",
      "                            \"policyRuleURI\": \"health_checker:2.0-stable\",\n",
      "                            \"parameters\": {\n",
      "                                \"unhealthy_threshold\": 2\n",
      "                            },\n",
      "                            \"settings\": {\n",
      "                                \"check_interval_sec\": 10\n",
      "                            }\n",
      "                        }\n",
      "                    },\n",
      "                    {\n",
      "                        \"values\": {\n",
      "                            \"name\": \"autoscaler\",\n",
      "                            \"policyRuleURI\": \"autoscaler:2.0-stable\",\n",
      "                            \"parameters\": {\n",
      "                                \"target_gpu_utilization\": 0.8\n",
      "                            },\n",
      "                            \"settings\": {\n",
      "                                \"scale_up_cooldown\": 45,\n",
      "                                \"scale_down_cooldown\": 900\n",
      "                            }\n",
      "                        }\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat allocation.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd6a6a",
   "metadata": {},
   "source": [
    "## 4. Triggering and Observing Distribution\n",
    "\n",
    "To test the load balancer, we need multiple replicas of a block and a client that sends requests. The load balancer, guided by our policy, will distribute these requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fea68194-6d06-438d-82d4-fff944084790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": \"block with same ID already exists\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#first create the Block and show in K8s Dashboard\n",
    "!curl -X POST -d @./allocation.json -H \"Content-Type: application/json\" http://MANAGEMENTMASTER:30501/api/createBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96361667-e26d-4f61-b46d-087e1669768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test with 2 concurrent requests.\n",
      "Each request will have 1600 input tokens and ask for max 50 output tokens.\n",
      "Session session-6f5162af-2650-4f1f-8911-1cb3b85a947e: Latency: 4.61s\n",
      "Session session-8672805d-bb75-4b7f-8d16-41eb041a8ec7: Latency: 8.41s\n",
      "Test finished.\n"
     ]
    }
   ],
   "source": [
    "!python3 client_test_token_loadbalancer.py  --input-tokens=1600  --max-output-tokens=50 --num-requests=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2fa6c",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test with 15 concurrent requests.\n",
      "Each request will have 100 input tokens and ask for max 100 output tokens.\n"
     ]
    }
   ],
   "source": [
    "!python3 client_test_token_loadbalancer.py  --max-output-tokens=100 --num-requests=15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2dacd6",
   "metadata": {},
   "source": [
    "### Observing the Results\n",
    "\n",
    "You can monitor the distribution of requests in the logs.\n",
    "\n",
    "\n",
    "**In K8s Logs:**\n",
    "- `K8s dashboard` available at https://CLUSTER1MASTER:32319/#/login\n",
    "- The load balancer service will log its decisions, including the scores it calculated for each block and which block it chose for each request. \n",
    "- You can also inspect the logs of the individual block replicas to see which requests they received."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
