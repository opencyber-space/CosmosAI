This document describes a real-time pose estimation algorithm component (pose-estimation-rt, v0.0.1) for keypoint detection.  It's a GPU-required PyTorch model using HRNet-W32 backbone and SimpleBaseline head, pre-trained on a combined COCO, MPII, and custom dataset for diverse poses and camera angles, achieving 0.72 AP.  It supports batching (default size 4) and requires 640x640 input frames. Key configuration options include confidence threshold, FP16 usage, CUDA usage, decoder dimensions, batch size, model type (large, medium, small), decoder type (DALI, TURBO), and interpolation type.  Benchmarking on an NVIDIA T4 with a batch size of 4 and FP16 precision shows a throughput of ~33.3 FPS, utilizing ~75% GPU and ~4GB of memory. It consumes RGB frames and person detections in OD1 format and produces keypoint coordinates, pose confidence, and bounding boxes, also in OD1 format.