This document describes a YOLOv7-based pose estimation algorithm component for detecting people and their keypoints.  It's a GPU-requiring node algorithm with a stable v0.0.1 release, using the `pose-estimation:latest` Docker image.  Configured for 1920x1080 input frames with batching support up to size 8, it offers configurable parameters for confidence, NMS IOU, and various settings like FP16 usage and decoder type.  The model is pre-trained on COCO Pose and custom surveillance data, targeting 17 keypoints in a COCO format.  Benchmarking on an NVIDIA T4 shows throughput up to 33.3 FPS with batch size 4, and an average precision of 0.68.  The component requires a minimum of 3GB GPU memory and uses Python 3.8, CUDA 11.0, and cuDNN 8.0 on Ubuntu 20.04.