This document describes how to estimate CPU and memory requirements for pods based on the expected event rate per minute (`eventsReceivedPerTick(60seconds)`).  It explains how to use data from existing pod metrics (presumably provided in separate CSV files) to create a predictive model, suggesting linear regression or trend line fitting.  Users should find the closest data points in the table to their target event rate and interpolate linearly to estimate the corresponding CPU (millicores) and memory (GB) needs.  A Python code example is provided to automate this process, emphasizing the importance of interpolation and avoiding extrapolation for accurate resource allocation during scaling and deployment planning.