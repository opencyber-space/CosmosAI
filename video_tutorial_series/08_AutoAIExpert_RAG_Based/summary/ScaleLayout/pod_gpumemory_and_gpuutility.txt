This table shows GPU memory usage (`used_gpu_memory`) and average GPU utilization (`avg_gpu_util`) for different processing blocks across multiple nodes and GPUs.  Its purpose is to help estimate GPU resource requirements for scaling deployments.  The table lists each block's ID, process ID (PID), GPU index, GPU name, used GPU memory, average GPU utilization, node name, and the block's corresponding workload mapping.  Critically, the `avg_gpu_util` represents the *total* utilization of a given GPU index on a specific node, shared by all blocks on that GPU.  By correlating this data with the workload intensity (e.g., events/frames per second derived from `pod_metrics`), users can predict the necessary GPU resources for new or expanded workloads, aiding in efficient resource allocation during ScaleLayout planning and Set Creation.